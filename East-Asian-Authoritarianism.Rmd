---
title: "East Asian Authoritarianism"
author: "Jack Carter"
date: "5/11/2021"
output: github_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

options(dplyr.summarise.inform = FALSE)
library(dplyr, warn.conflicts = FALSE)
library(tidyverse)
library(tidyr)
library(tidytext)
library(ggrepel)
library(readxl)
library(ggplot2)
library(ggthemes)
library(naniar)
library(patchwork)
library(rvest)
library(pdftools)
library(patchwork)
library(here)
library(rtweet)
library(knitr)
library(tibble)

# read in spreadsheet data without including duplicate 
# tweets  from the previous week's search results.  
read_data <- function(file_name, previous_file=NULL) {
  file <- read_twitter_csv(here("data", file_name)) %>%
    mutate(status_id = as.numeric(status_id))
  if(!is.null(previous_file)) file <- file %>%
      filter(status_id > max(previous_file$status_id))
  return(file)
}

# breaks the text down into single words, 
# inner joins them with the NRC library 
# and counts the frequency of each sentiment. 
join_words_with_sentiment <- function(raw_tweets) {
  nrc_sentiment <- get_sentiments("nrc") %>% select(word, sentiment)
  words <- raw_tweets %>%
    unnest_tokens(word, text) %>%
    left_join(nrc_sentiment, by = "word") %>%
    mutate(sentiment = replace_na(sentiment, replace = "none")) %>%
    filter(!word %in% stop_words$word) %>%
    group_by(search, region, country, sentiment, week) %>%
    count(sentiment) %>%
    rename(words = "n")
    return(words)
}

# calculates the sentiment for each region
# as a percentage of total words. 
calculate_regional_percentages <- function(words) {
  final_value <- words %>%
    group_by(region) %>%
    mutate(total_words = sum(words),
           percent = (words / total_words)*100) %>%
    select(region, sentiment, percent) %>%
    group_by(region, sentiment) %>%
    summarise(percent = sum(percent))
}

# calculates the sentiment for each week
# as a percentage of total words. 
calculate_week_percentages <- function(words) {
  final_value <- words %>%
    group_by(region, week) %>%
    mutate(total_words = sum(words),
           percent = (words / total_words)*100) %>%
    select(region, week, sentiment, percent) %>%
    group_by(region, week, sentiment) %>%
    summarise(percent = sum(percent))
}

# calculates the sentiment for each country
# as a percentage of total words. 
calculate_country_percentages <- function(words) {
  final_value <- words %>%
    group_by(country, region) %>%
    mutate(total_words = sum(words),
           percent = (words / total_words)*100) %>%
    select(region, country, sentiment, percent) %>%
    group_by(region, country, sentiment) %>%
    summarise(percent = sum(percent))
}

# calculates the sentiment for each search term
# as a percentage of total words. 
calculate_search_term_percentages <- function(words) {
  final_value <- words %>%
    group_by(region, search) %>%
    mutate(total_words = sum(words),
           percent = (words / total_words)*100) %>%
    select(region, search, sentiment, percent) %>%
    group_by(region, search, sentiment) %>%
    summarise(percent = sum(percent))
}

# reads in the data from csv files. 
week_11_05_2021 <- read_data(file_name="11-05-2021.csv")
week_18_05_2021 <- read_data(file_name="18-05-2021.csv", 
                             previous_file=week_11_05_2021)
week_25_05_2021 <- read_data(file_name = "25-05-2021.csv",
                             previous_file = week_18_05_2021)

# binds the data together as a single object. 
combined_raw_data <- week_11_05_2021 %>%
  rbind(week_18_05_2021) %>%
  rbind(week_25_05_2021)

# counts the frequency of different NRC sentiments.  
words <- join_words_with_sentiment(combined_raw_data) %>%
  spread(sentiment, words) %>%
  rename("Anticipation" = "anticipation", "Joy" = "joy", "Trust" = "trust",
         "Anger" = "anger", "Disgust" = "disgust", "Fear" = "fear") %>%
  gather(sentiment, words, -c(1:4)) %>%
  mutate(words = replace_na(words, replace = 0)) 

# Calculates each sentiment as a percentage of 
# total words based on region. 
regional_percentages <- calculate_regional_percentages(words)

# Calculates each sentiment as a percentage of 
# total words based on week 
week_percentages <- calculate_week_percentages(words)

# calculates each sentiment as a percentage of 
# total words based on search term.  
search_term_percentages <- calculate_search_term_percentages(words) 

# calculates each sentiment as a percentage of 
# total words based on country.  
country_percentages <- calculate_country_percentages(words) 

# my personal plot theme for data visualizations. 
my_theme <- theme_economist_white(gray_bg = FALSE) +
  theme(plot.title = element_text(hjust = 0.5, 
                                  vjust = 12, 
                                  size = 10, 
                                  color = "#474747"),
        plot.margin = unit(c(1.5, 1, 1.5, 1), "cm"),
        axis.text = element_text(size = 9, 
                                 color = "gray30"),
        axis.text.x=element_text(vjust = -2.5),
        axis.title.x = element_text(size = 9, 
                                    color = "gray30", 
                                    vjust = -10),
        axis.title.y = element_text(size = 9, 
                                    color = "gray30", 
                                    vjust = 10),
        legend.direction = "vertical", 
        legend.position = "right",
        legend.title = element_blank(),
        legend.text = element_text(size = 12, 
                                   color = "gray20"),
        legend.margin=margin(1, -15, 1, 0),
        legend.spacing.x = unit(0.25, "cm"),
        legend.key.size = unit(1, "cm"), 
        legend.key.height = unit(0.75, "cm"),
        strip.text = element_text(hjust = 0.5, 
                                  vjust = 1, 
                                  size = 10, 
                                  color = "#474747"),
        panel.spacing = unit(2, "lines"))

# data tables: 
# power distance scores based Hofstede's cultural
# dimension's index. 
power_distance_scores <- tibble(country = c("China", "Hong Kong","Singapore", 
                                              "US", "South Korea","UK", 
                                              "Taiwan", "New Zealand", "South Africa", 
                                              "Australia"),
                                region = c("Sinic", "Sinic", "Sinic", 
                                           "Anglo", "Sinic", "Anglo", 
                                           "Sinic", "Anglo", "Anglo", 
                                           "Anglo"),
                                power_distance = c(80, 68, 74, 
                                                     40, 60, 35,
                                                     58, 22, 49, 
                                                     36))

# democracy scores based on The Economist Intelligence 
# Unit's (EIU) democracy index. 
democracy_scores <- tibble(country = c("China", "Vietnam", "Hong Kong",
                                       "Singapore", "US", "South Korea",
                                       "UK", "Taiwan", "Canada",
                                       "New Zealand", "South Africa", "Australia"),
                           region = c("Sinic", "Sinic", "Sinic",
                                      "Sinic", "Anglo", "Sinic",
                                      "Anglo", "Sinic", "Anglo",
                                      "Anglo", "Anglo", "Anglo"),
                           "Overall" = c(2.27, 2.94, 5.57,
                                       6.03, 7.72, 8.01,
                                       8.54, 8.94, 9.24,
                                       9.25, 7.05, 8.96),
                           "Electoral Process" = c(0, 0, 3.17,
                                                 4.83, 9.17, 9.17,
                                                 10, 10, 9.58,
                                                 10, 7.42, 10),
                           "Functioning Government" = c(4.29, 2.86, 3.64,
                                               7.86, 6.79, 8.21,
                                               7.5, 9.64, 8.93,
                                               8.93, 7.14, 8.57),
                           "Political Participation" = c(2.78, 3.89, 5,
                                             4.44, 8.89, 7.22,
                                             8.89, 7.22, 8.89,
                                             8.89, 8.33, 7.78),
                           "Political Culture" = c(3.13, 5.63, 7.50,
                                       6.25, 6.25, 7.5,
                                       7.50, 8.13, 9.38,
                                       8.75, 5, 8.75),
                           "Civil Liberties" = c(1.18, 2.35, 8.53,
                                               6.76, 8.53, 7.94,
                                               8.82, 9.71, 9.41,
                                               9.71, 7.35, 9.71)) %>%
  gather(type, value, -c(1:2))

```

## **Summary**

This report analyzes anti-authority sentiment between Anglophone and Sinic countries. It finds that Sinic country Twitter users demonstrate less positive sentiment when using a collection of anti-authority words. This may be due to the differing influence of Confucian verses European enlightenment values.  

The rest of the report is organized into the following sections:

1. Authoritarian Tendencies
2. Sentiment Analysis

&nbsp;

## **1: Authoritarian Tendencies**

1.1: Power distance scores according to Hofstede's seminal cultural dimension's study. Power distance is the extent to which people accept unequal power in society *(Hofstede, 1980)*.

```{r, echo = FALSE, message = FALSE, warning = FALSE, dpi=600}

# power distance
power_distance_scores %>%
  ggplot(aes(x = country, y = power_distance, col = region)) +
  geom_point(alpha = 0.9) +
  geom_text_repel(aes(label=country), size = 2.25,
                  show.legend = FALSE,
                  max.overlaps = 5) +
  ggtitle("Power Distance") +
  xlab("") +
  ylab("Power Distance Score") +
  ylim(18, 82) +
  scale_color_manual(values = c("#0072B2", "#D55E00")) +
  theme_economist_white(gray_bg = FALSE) +
  my_theme +
  theme(axis.text.x=element_blank(),
        plot.margin = unit(c(1.5, 1.5, 1.5, 1.5), "cm"))

```

1.2: Aspects of democracy according to The Economist Intelligence Unit's Democracy Index *(EIU, 2020)*.

```{r, echo = FALSE, message = FALSE, warning = FALSE, dpi=600}

# aspects of democracy
democracy_scores %>%
  filter(!type == "Overall" & !type == "Functioning Government") %>%
  ggplot(aes(x = country, y = value, col = region)) +
  geom_point(alpha = 0.9) +
  geom_text_repel(aes(label=country), size = 2.25,
                  show.legend = FALSE,
                  max.overlaps = 5) +
  facet_wrap(~type) +
  ggtitle("Democracy") +
  xlab("") +
  ylab("EIU score") +
  ylim(0, 13) +
  scale_color_manual(values = c("#0072B2", "#D55E00")) +
  theme_economist_white(gray_bg = FALSE) +
  my_theme +
  theme(axis.text.x=element_blank(),
        plot.margin = unit(c(1.5, 1.5, 1.5, 1.5), "cm"))

```

&nbsp;

## **2: Sentiment Analysis**

The analysis collects tweets containing anti-authority words within a 50 mile range of Anglophone and Sinic country capitals from 11-05-2021 to present. A sentiment analysis is conducted using the NRC sentiment library. This is done by calculating how often words associated with certain sentiments occur relative to their regional total. Figures 2.1 and 2.2 show selected emotions while figures 2.3 to 2.5 show net sentiment (positive minus negative).

The collection of anti-authority words includes defy, disobey, oppose, protest, rebel, resist, revolt and riot. 

<br>

### Summary Statistics:

```{r, echo = FALSE, message = FALSE, warning = FALSE, dpi=600}

options(digits=3)

# total tweets for summary data
total_tweets <- sum(nrow(combined_raw_data))

# total words for summary data
total_words <- sum(words$words)

# regional tweets
regional_tweets <- combined_raw_data %>%
  mutate(Region = region) %>%
  group_by(Region) %>%
  summarise(Tweets = sum(tweets) / 10^3) %>%
  rename("Tweets (000s)" = Tweets)

# regional words
regional_words <- words %>%
  mutate(Region = region) %>%
  group_by(Region) %>%
  summarise(Words = sum(words) / 10^3) %>%
  rename("Words (000s)" = Words)

# Combined table
combined_table <- regional_tweets %>%
  left_join(regional_words) %>%
  group_by(Region) %>%
  mutate("Tweets (%)" = (`Tweets (000s)` / total_tweets) * 10^5,
         "Words (%)" = (`Words (000s)` / total_words) * 10^5) %>%
  ungroup()

# final regional summary table
final_regional_table <- combined_table %>%
  add_row("Region" = "Total",
          "Tweets (000s)" = sum(combined_table$`Tweets (000s)`),
          "Words (000s)" = sum(combined_table$`Words (000s)`),
          "Tweets (%)" = 100,
          "Words (%)" = 100)

kable(final_regional_table, align = 'c')

```

&nbsp;

### Emotions:

2.1: Selected positive emotions for tweets containing the anti-authority words. This is calculated as the number of words for each emotion expressed as a percentage of total words. 

```{r, echo = FALSE, message = FALSE, warning = FALSE, dpi=600}

# positive emotions
regional_percentages %>%
  filter(sentiment %in% c("Joy", "Trust")) %>%
  mutate(sentiment = factor(sentiment, levels = c("Joy", "Trust"))) %>%
  ggplot(aes(x = region, y = percent, fill = region)) +
  geom_bar(stat = "identity", position = "dodge") +
  facet_wrap(~sentiment, ncol = 2) +
  ggtitle("Positive") +
  ylab("% of Total Words") +
  xlab("") +
  scale_fill_manual(values = c("#0072B2", "#D55E00")) +
  my_theme +
  theme(axis.text.x=element_blank())

```

2.2: Selected negative emotions for tweets containing the anti-authority words. This is calculated as the number of words for each emotion expressed as a percentage of total words. 

```{r, echo = FALSE, message = FALSE, warning = FALSE, dpi=600}

# negative emotions
regional_percentages %>%
  filter(sentiment %in% c("Anger", "Fear")) %>%
  mutate(sentiment = factor(sentiment, levels = c("Anger", "Fear"))) %>%
  ggplot(aes(x = region, y = percent, fill = region)) +
  geom_bar(stat = "identity", position = "dodge") +
  facet_wrap(~sentiment, ncol = 2) +
  ggtitle("Negative") +
  ylab("% of Total Words") +
  xlab("") +
  scale_fill_manual(values = c("#0072B2", "#D55E00")) +
  my_theme +
  theme(axis.text.x=element_blank())

```

### Net Sentiment:

2.3: The net sentiment for each region. Net sentiment is calculated as positive minus negative words expressed as a percentage of total words.  

```{r, echo = FALSE, message = FALSE, warning = FALSE, dpi=600}

# region
regional_percentages %>%
  spread(sentiment, percent) %>%
  mutate(net = positive - negative) %>%
  gather(sentiment, percent, -1) %>%
  filter(sentiment == "net") %>%
  ggplot(aes(x = region, y = percent, fill = region)) +
  geom_bar(stat = "identity", position = "dodge") +
  ggtitle("Region") +
  ylab("% of Total Words") +
  xlab("") +
  scale_fill_manual(values = c("#0072B2", "#D55E00")) +
  my_theme +
  theme(axis.text.x=element_blank())

```

2.4: The net sentiment for each week during the data collection process. Net sentiment is calculated as positive minus negative words expressed as a percentage of total words. 

```{r, echo = FALSE, message = FALSE, warning = FALSE, dpi=600}

# week
week_percentages %>%
  spread(sentiment, percent) %>%
  mutate(net = positive - negative) %>%
  gather(sentiment, percent, -c(1:2)) %>%
  filter(sentiment == "net") %>%
  ggplot(aes(x = week, y = percent, fill = region)) +
  geom_bar(stat = "identity", position = "dodge") +
  ggtitle("Week") +
  ylab("% of Total Words") +
  xlab("") +
  scale_fill_manual(values = c("#0072B2", "#D55E00")) +
  my_theme +
  theme(axis.text.x=element_blank())

```

2.5: The net sentiment for each country. Net sentiment is calculated as positive minus negative words expressed as a percentage of total words.  

```{r, echo = FALSE, message = FALSE, warning = FALSE, dpi=600}

# labels for the countries plot
country_labels <- c("AU", "CA", "NZ", "SA", "UK", "US",
                    "CH", "HG", "SG", "KR", "TW", "VT")

# selected countries 
country_percentages %>%
  spread(sentiment, percent) %>%
  mutate(net = positive - negative,
         country = factor(country, 
                          levels=c("Australia", "Canada", "New Zealand", 
                                   "South Africa", "UK", "US", 
                                   "China",  "Hong Kong", "Singapore", 
                                   "South Korea", "Taiwan", "Vietnam"))) %>%
  gather(sentiment, percent, -c(1:2)) %>%
  filter(sentiment == "net") %>%
  ggplot(aes(x = country, y = percent, fill = region)) +
  geom_bar(stat = "identity", position = "dodge") +
  geom_text(aes(label=country_labels),
             position=position_stack(vjust=0.5), 
             colour="white",
             size = 2.25,
             show.legend = FALSE) +
  facet_wrap(~region, scales = "free") +
  ggtitle("Country") +
  ylab("% of Total Words") +
  xlab("") +
  ylim(-7, 0) +
  scale_fill_manual(values = c("#0072B2", "#D55E00")) +
  my_theme +
  theme(axis.text.x=element_blank())

```

2.6: The net sentiment for each search term. Net sentiment is calculated as positive minus negative words expressed as a percentage of total words.  

```{r, echo = FALSE, message = FALSE, warning = FALSE, dpi=600}

# search terms
search_term_percentages %>%
  spread(sentiment, percent) %>%
  mutate(net = positive - negative) %>%
  gather(sentiment, percent, -c(1:2)) %>%
  filter(sentiment == "net") %>%
  ggplot(aes(x = region, y = percent, fill = region)) +
  geom_bar(stat = "identity", position = "dodge") +
  facet_wrap(~search) +
  ggtitle("Search Term") +
  ylab("% of Total Words") +
  xlab("") +
  scale_fill_manual(values = c("#0072B2", "#D55E00")) +
  my_theme +
  theme(axis.text.x=element_blank())

```

&nbsp;

## **Sources**

- EIU (2020) https://www.eiu.com/n/campaigns/democracy-index-2020/

- Hofstede (1980) https://www.tandfonline.com/doi/abs/10.1080/00208825.1980.11656300?journalCode=mimo20

- Mohammad (2021) https://saifmohammad.com/WebPages/NRC-Emotion-Lexicon.htm

- Twitter (2021) https://developer.twitter.com/en/apply-for-access

&nbsp;
&nbsp;
&nbsp;


